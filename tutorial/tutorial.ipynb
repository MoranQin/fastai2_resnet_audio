{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2_resnet_audio.model import *\n",
    "from fastai2_resnet_audio.data import *\n",
    "from fastai2.vision.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fastai2-resnet-audio tutorial\n",
    "\n",
    "> Tutorial for fastai2-resnet-audio - Dataset used: https://github.com/earthspecies/open_collaboration_on_audio_classification/blob/master/introduction.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/Users/florian/.fastai/data/macaques_24414Hz')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data('https://storage.googleapis.com/ml-animal-sounds-datasets/macaques_24414Hz.zip')\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoaders\n",
    "\n",
    "Create DataBlock and DataLoaders with AudioBlock and AudioTransforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 0.5\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dblocks = DataBlock(blocks = (AudioBlock,CategoryBlock),\n",
    "                 get_items=get_files, \n",
    "                 splitter=RandomSplitter(seed=42),\n",
    "                 get_y=parent_label,\n",
    "                 item_tfms=[AudioRandomCrop(length=length),\n",
    "                            AudioFixLength(length=length),\n",
    "                           ],\n",
    "                 batch_tfms=[AudioAddNoise(device=device)]\n",
    "                 )\n",
    "\n",
    "dls=dblocks.dataloaders(path, bs=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorAudio([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       " \n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       " \n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       " \n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       " \n",
       "         [[ 1.3763e-02,  2.7649e-02,  4.1534e-02,  ...,  6.1035e-05,\n",
       "           -1.0071e-03, -2.0752e-03]]]),\n",
       " TensorCategory([4, 3, 2, 1, 5, 1, 3, 3, 4, 0, 4, 1, 5, 5, 3, 3, 2, 0, 6, 2, 6, 1, 4, 7,\n",
       "         0, 2, 5, 0, 3, 2, 7, 5, 6, 6, 6, 5, 6, 3, 3, 6, 7, 2, 3, 2, 0, 5, 0, 4,\n",
       "         3, 6, 0, 4, 5, 4, 6, 3, 0, 0, 6, 1, 5, 3, 1, 1, 5, 1, 2, 3, 3, 6, 7, 2,\n",
       "         2, 1, 5, 3, 6, 5, 5, 2, 2, 2, 6, 2, 1, 3, 7, 5, 5, 0, 6, 7, 3, 2, 7, 0,\n",
       "         5, 2, 6, 4, 6, 0, 1, 0, 4, 4, 4, 4, 0, 2, 3, 7, 6, 3, 2, 1, 4, 6, 1, 7,\n",
       "         6, 3, 4, 0, 2, 2, 0, 7]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.one_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Create **model configuration** - available configurations are resnet1d18 and resnet1d34.\n",
    "\n",
    "You have to adopt the **num_classes** parameter according to the number of classes of your dataset (8 classes for this dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = resnet1d18\n",
    "config['num_classes'] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'block': fastai2_resnet_audio.model.ResidualBlock,\n",
       " 'layers': [2, 2, 2, 2],\n",
       " 'in_channels': 64,\n",
       " 'kernel_size': 15,\n",
       " 'stride': 4,\n",
       " 'num_classes': 8}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create **model** using config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNetAudio(**config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learner + Training\n",
    "\n",
    "Creating the **learner and trainig** the model is straight forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, model, metrics=accuracy, cbs=ShowGraphCallback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(5, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tune pretrained model on different dataset\n",
    "\n",
    "**Steps**\n",
    "- create DataLoaders\n",
    "- create model with same config (num_classes) as the pretrained model\n",
    "- create learner\n",
    "- load pretrained model weights with learn.load(\"pretrained.pth\")\n",
    "- call **replace_head** with num_classes=number classes new dataset\n",
    "\n",
    "Lets pretend the macaques dataset had 20 instead of 8 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data('https://storage.googleapis.com/ml-animal-sounds-datasets/macaques_24414Hz.zip')\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 0.5\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dblocks = DataBlock(blocks = (AudioBlock,CategoryBlock),\n",
    "                 get_items=get_files, \n",
    "                 splitter=RandomSplitter(seed=42),\n",
    "                 get_y=parent_label,\n",
    "                 item_tfms=[AudioRandomCrop(length=length),\n",
    "                            AudioFixLength(length=length),\n",
    "                           ],\n",
    "                 batch_tfms=[AudioAddNoise(device=device)]\n",
    "                 )\n",
    "\n",
    "dls=dblocks.dataloaders(path, bs=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model was pretrained on dataset with 8 classes, so create config with 8 classes to load the pretrianed model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = resnet1d18\n",
    "config['num_classes'] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, model, metrics=accuracy, cbs=ShowGraphCallback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(\"saved_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading the pretrained weights we can **replace the last linear layer**. In this example for a dataset with **20 classes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=20, bias=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_head(learn.model, num_classes=20)\n",
    "model[-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('fastai2': conda)",
   "language": "python",
   "name": "python38164bitfastai2conda8f00f3245bb84569a74bc3f339ede271"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
